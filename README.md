# LLM Model Performance Analysis
<img width="808" alt="image" src="https://github.com/user-attachments/assets/59e08725-4008-46ed-8dd6-a5012642e9b9">
<img width="758" alt="image" src="https://github.com/user-attachments/assets/a22f4ed6-98b2-4286-8460-159a2814c314">
<img width="693" alt="image" src="https://github.com/user-attachments/assets/491eaf60-634e-490a-8d52-74fef770f2e8">
<img width="960" alt="image" src="https://github.com/user-attachments/assets/ffa20c7b-29ea-4ff1-a380-3338576c9b8d">
<img width="569" alt="image" src="https://github.com/user-attachments/assets/2d771f4c-9a03-4ac7-b45d-b6c185761e22">


## Overview
This project aims to analyze and compare the rewriting capabilities of various large language models (LLMs) across 24 different text categories. By doing so, we aim to identify which models perform best in specific domains.

## Structure
- **Category Texts:** 24 categories, each with 50 texts.
- **Models:** Six LLMs are employed to rewrite the texts.
- **Evaluation:** A custom evaluation system, called "Judge" (GPT-4o), scores the rewritten texts based on defined metrics.


## Sample Result
The results will include detailed scores for each model across different categories, allowing for an in-depth comparison of their performance.
<img width="265" alt="image" src="https://github.com/user-attachments/assets/db1edb5e-5d08-448e-8160-2970eed2e181">
<img width="1111" alt="image" src="https://github.com/user-attachments/assets/fb41fc89-ed8a-4a69-923b-19573b6f9834">
<img width="612" alt="image" src="https://github.com/user-attachments/assets/163d7a6e-65a4-40d7-8f4c-6273a15e8cf4">


## Conclusion
This analysis provides insights into which LLMs are best suited for different types of content, helping guide future applications and research in the field of natural language processing.

